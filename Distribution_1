import math, random, numpy, multiprocessing

random.seed(0)
# Nombre de learner, temps total, nombre d'hypercubes
M = 2
T = 100000
m_T = 2
D = 2
nb_m = m_T**D

# Nombre d'arms par learner
F = [2,2]

# Borne maximale des arms
Fmax = max(F)

# Paramètres de fonctions
z = 0.5

Fi = F[0]  # Nombre d'arms
Fj = F[0]

# Informations et contexte
x_it = numpy.zeros((T,M,D))

for t in range(0,T):
    for m in range(0,M):
        x_it[t,m,] = numpy.random.uniform(low=0.0, high=1.0,size=2)



# Liste d'utilisation pour chaque learner
C_it = list()
C_jt = list()

# Construction d'une classe de learner : avec les attributs d'intérêt. Note : il est possible d'ajouter des arguments
# comme le nombre de bras (pour l'instant faisons simple).

# Attention à la façon dont on va traiter les choses par la suite. Il faut que le process reste vivant tout au long
# des calculs (et non pas qu'on en créé pour chaque date).

class Learner(multiprocessing.Process):

    def __init__(self, id, task_queue):
        multiprocessing.Process.__init__(self)
        self.task_queue = task_queue
        self.id = id
        self.Eps_i_jpt = numpy.zeros((nb_m, M-1))
        self.count_i_jpt = numpy.zeros((nb_m, M-1))
        self.Eps_i_fpt = numpy.zeros((nb_m, Fi))
        self.count_i_fpt = numpy.zeros((nb_m, Fi))
        self.count_i = numpy.zeros((nb_m))
        self.N_itr_jpt = numpy.zeros((nb_m, M-1))

    # Tache à accomplir : à chaque fois récupérer une tâche dans la queue et effectuer le travail. Si la tâche est
    # None alors cesser de travailler (sortie du loop).

    def run(self):
        while True:
            next_task = self.task_queue.get()
            if next_task is None:
                # Poison pill means shutdown
                print("Reward de %s en activant un de ses bras :" % self.id)
                print(self.Eps_i_fpt)
                print("Reward de %s après avoir été sollicité par un autre learner" % self.id)
                print(self.Eps_i_jpt)
                self.task_queue.task_done()
                break
                
            ###
            
            Des tâches à effectuer
            
            ###

            self.task_queue.task_done()
        return



# Information sur les rewards

position = numpy.zeros((T,M))

for t in range(0,T):
    for m in range(0,M):
        position[t,m] = sum((int(x_it[t,m,i]*m_T))*m_T**i for i in range (0,m_T))


# D'après ces fonctions de contrôle (p.6),
# on détermine successivement s'il faut entrer en phase :
  # d'exploration de ses bras persos
  # ou d'entraînement
  # ou de jeu


def D_1(t):
    return math.log(t)*t**z

def D_2(t):
    return Fmax*math.log(t)*t**z

def D_3(t):
    return Fmax*math.log(t)*t**z


# Fonction de coût (ici uniforme quelque soit le choix)
def d_i_k():
    return 1

# Reward (ici très simple, elle incorpore même la réponse directement et le coût)

# Ici les machines sont de manière déterministe spécialisées en un ensemble précis (0,1) et (2,3) et leur bras dans un
# sous ensemble de ces mêmes ensembles.

def reward(p,id,choix): # p = espace / id = identifiant du learner (1 ou 2) / choix = choix de l'arm
    if id == 0:
        if p == choix:
            return 1
        else:
            return -1
    else:
        if p == choix+2:
            return 1
        else:
            return -1




if __name__ == '__main__':

    # Construction d'une Queue
    tasks = multiprocessing.JoinableQueue()

    # Construction des learners
    learners = [Learner(i, tasks) for i in range(M)]

    # Début d'activité
    for l in learners:
        l.start()

    # Ajout des informations dans la Queue
    for t in range(T):
        for m in range(M):
            tasks.put(x_it[t, m, ])
